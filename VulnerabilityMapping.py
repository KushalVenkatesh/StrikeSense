import urllib.request
import urllib
import os
from bs4 import BeautifulSoup
import mysql.connector


#importing from package
import AuthDB
from HostDiscovery import current_proj_path

def VulnToCSV(query_string):
    r = urllib.request.urlopen("https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword="+query_string)
    source_code = r.read()
    soup = BeautifulSoup(source_code, 'html.parser')
    table = soup.find('div', {"id" : 'TableWithRules'})
    rows=table.find_all("tr")
    for tr in rows:
        cols = tr.find_all('td')
        #This is a sanity check to continue if it finds any col value empty
        if cols==[]:
            continue
        p = cols[0].text.strip()
        d = cols[1].text.strip()

        CsvName = "VulnMap_"
        CsvName += query_string.replace(' ', '_').strip()
        CsvName += ".csv"

        CurrentMappings = os.listdir('Mappings')
        FullFilePath = current_proj_path+"/"+CsvName

        if CsvName not in CurrentMappings:
            with open(FullFilePath, "a") as out_file:
                out_string = " "
                out_string += str(p)+","
                out_string += str(d)
                out_string += str("\n")
                out_file.write(out_string)

def StartMapping():
    print("[+] Started Vulnerability mapping.")
    query = 'select distinct(windows_ver) from scanner_computer_info;'
    cnx = mysql.connector.connect(**AuthDB.config)
    cursor = cnx.cursor(buffered=True)
    cursor.execute(query)
    row_data = cursor.fetchone()
    VersionList = []
    while row_data:
        VersionList.append(str(row_data[0]))
        row_data = cursor.fetchone()
    cursor.close()
    cnx.close()
    TotalMappings = 0
    for item in VersionList:
        if item.strip():
            TotalMappings += 1
            VulnToCSV(item)
    print("[+] "+str(TotalMappings)+" distinct vulnerable systems mapped and reports published.")
